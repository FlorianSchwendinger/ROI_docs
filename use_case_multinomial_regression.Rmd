---
title: "Multinomial logistic regression"
author: 
- "Laura Vana 
- [Email](mailto:laura.vana@wu.ac.at)"
date: "July 6, 2020"
---

# Model
The [multinomial logistic model](https://en.wikipedia.org/wiki/Multinomial_logistic_regression) 
(or logit model) is widely used in regression analysis to model unordered categorical variables. 

## Likelihood
Assume we have a categorical dependent variable $y_{i} \in {1, \ldots, J}$ which can take a value out of $J$ unordered categories for each observation $i = 1,\ldots, n$. Moreover, for each observation we observe a vector of $p$ covariates $\boldsymbol x_i$ which do not depend on the category (this assumption can easily be relaxed). Let us create a binary vector $\boldsymbol {\tilde y}_i$ where $\tilde y_{ij}=1$ if $y_i=j$. The likelihood is given by: 
$$
\ell(\boldsymbol\beta_1, \ldots, \boldsymbol\beta_J) = \prod_{i=1}^n\prod_{j=1}^J\left[\frac{\exp(\boldsymbol x^\top_i \boldsymbol\beta_j)}{\sum_{l=1}^J\exp(\boldsymbol x_i^\top \boldsymbol\beta_l)}\right]^{\tilde y_{ij}}
$$
and the log-likelihood is:
$$
\sum_{i=1}^n \sum_{j=1}^J \tilde y_{ij}
\log\left[\frac{\exp(\boldsymbol x^\top_i  \boldsymbol\beta_j)}{\sum_{l=1}^J\exp(\boldsymbol x_i^\top \boldsymbol\beta_l)}\right]=
\sum_{i=1}^n \left(\sum_{j=1}^J \tilde y_{ij}\boldsymbol x^\top_i  \boldsymbol\beta_j\right) - \mathrm{log}\sum_{l=1}^J\exp(\boldsymbol x_i^\top \boldsymbol\beta_l)
$$
For identification purposes one must set the $\boldsymbol\beta$ equal to 0 for one baseline category.

## Conic program
The second term of the log-likelihood can be modeled by conic programming. Assuming that the first category is the baseline category, 
the problem of maximizing the log-likelihood can be written as:
\begin{align}
\min_{\substack{\boldsymbol\beta_l,\\ l=1,\ldots,J}}\quad &- \sum_{i=1}^n \left(\sum_{j=1}^J \tilde y_{ij}\boldsymbol x^\top_i  \boldsymbol\beta_j\right) + \sum_{i=1}^n t_i\\
\text{s.t.}\quad  & u^{1}_i + \ldots + u^{J}_i  \leq 1, \quad \forall i=1,\ldots, n\\
& (-t_{i}, 1, u^J_{i})^\top\in\mathcal{K}_\text{expp}\\
 &(x_i^\top\boldsymbol \beta_j - t_i, 1, u^j_i)^\top\in\mathcal{K}_\text{expp}, \quad \forall j = 1,\ldots,J-1.
\end{align}

# Estimation

In **R** several packages have built in functionality for estimating the multinomial logistic regression.  Among others, the `multinom()` function from **nnet** package (Venables & Ripley, 2002),
the `vglm()` and `multinomial()` functions of the **VGAM** package (Yee, 2010) and the `mlogit()` function from the **mlogit** package (Croissant, 2020). 

When implementing the function in ROI, the conic program above
must be specified by constructing the appropriate matrices. 

```{r use_case_multinomial_regression_mlogit_function}
mlogit_roi <- function(X, y, solver = "auto", ...) {
  stm <- simple_triplet_matrix
  stzm <- simple_triplet_zero_matrix
  y <- as.numeric(y)
  stopifnot(is.vector(y), length(y) == nrow(X))
  ymat <- model.matrix(~ as.factor(y))[, - 1] 
  xtilde <- model.matrix(~ 0 + ymat : X)    
  ytilde <- (y != min(y)) + 0 # indicator taking zero for category to be excluded
  n <- nrow(X); p <- ncol(X); J <- max(y); ptilde <- ncol(xtilde)
  
  i <- 3 * seq_len(n) - 2 ## triplets for for cones
  ## Variables: beta_2, .., beta_J, t_i, u^1,..., u^J
  op <- OP(c(- (ytilde %*% xtilde), rep.int(1, n), double(n * J)), maximum = FALSE)
  Ct <- stm(i, seq_len(n), rep.int(1, n), 3 * n, n)  
  Cu <- stm(i + 2, seq_len(n), rep.int(-1, n), 3 * n, n)
  Clist <- lapply(seq_len(J), function(j) {
    Cx <- if(j == 1) stzm(3 * n, ptilde) else
                 stm(rep(i, p), rep((seq_len(p) - 1) * (J - 1) + j - 1, each = n),
                  -drop(X), 3 * n, ptilde)
    CC <- cbind(Cx, Ct, stzm(3 * n, n * (j - 1)), Cu, stzm(3 * n, n * (J - j)))
  })
  
  C <- do.call("rbind", Clist)
  cones <- K_expp(J * n)
  rhs <- rep(c(0, 1, 0), n * J)
  
  CL <- cbind(stzm(n, ptilde + n),
              stm(rep(seq_len(n), J), seq_len(n * J), rep.int(1, n * J), n, n * J))
  
  rhs <- rep(c(0, 1, 0), n * J)
  constraints(op) <- rbind(C_constraint(C, cones, rhs),
                           L_constraint(CL, 
                                        dir = rep("<=", nrow(CL)), 
                                        rhs =  rep(1, nrow(CL))))
  
  bounds(op) <- V_bound(ld = -Inf, nobj = ncol(C))
  ROI_solve(op, solver = solver, ...)
}
```

# Heating example
We using the `Heating` data set from the `mlogit` package as an illustration:s
```{r  use_case_multinomial_regression_data1}
if(!require("mlogit")) install.packages("mlogit"); library("mlogit")
if(!require("nnet")) install.packages("nnet"); library("nnet")
data("Heating", package = "mlogit")
```

We estimate the model using the function `multinom()` for the **nnet** package, which uses a general purpose solver.
```{r use_case_multinomial_regression_example1_nnet}
coef(nnet::multinom(depvar ~ rooms + region, data = Heating))
```

Now using **ROI**. 
```{r use_case_multinomial_regression_example1_roi}
library(ROI)
library(ROI.plugin.ecos)
library(slam)
y <- Heating$depvar
X <- model.matrix(~ rooms +  region, data = Heating)
res <- mlogit_roi(X, y)
s2 <- solution(res)

matrix(s2[seq_len((max(as.numeric(y)) - 1) * ncol(X))], 
       ncol = ncol(X))
```

# Fishing example
Using the `Fishing` data set in **mlogit**, we estimate the multinomial model introduced in the first section using the function `mlogit()` from the **mlogit** package
```{r use_case_multinomial_regression_example1_mlogit}}
data("Fishing", package = "mlogit")
Fish <- dfidx(Fishing, varying = 2:9, shape = "wide", choice = "mode")
coef(mlogit(mode ~ 0 | income, data = Fish))
```
In **ROI**:
```{r use_case_multinomial_regression_example2_roi}
y <- Fishing$mode
X <- model.matrix(~ income, data = Fishing)
res2 <- mlogit_roi(X, y)
nam <- apply(expand.grid(levels(y)[-1], colnames(X)), 1,
             function(x) paste0(x[2], ":", x[1]))

s1 <- solution(res2)[1:6]
names(s1) <- nam 
s1
```



# References

* Croissant, Y. (2020). mlogit: Multinomial Logit Models. R package version 1.1-0.
  https://CRAN.R-project.org/package=mlogit

* Venables, W. N. & Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth Edition.
  Springer, New York. ISBN 0-387-95457-0

* Yee, T. W. (2010). The VGAM Package for Categorical Data Analysis. Journal of
  Statistical Software, 32(10), 1-34. URL http://www.jstatsoft.org/v32/i10/.